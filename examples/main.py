import asyncio
import inspect
import logging
from lightrag import LightRAG, QueryParam
from lightrag.llm.ollama import ollama_model_complete, ollama_embed
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens"

logging.basicConfig(format="%(levelname)s:%(message)s", level=logging.INFO)

# Kh·ªüi t·∫°o LightRAG
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="qwen2m",
    llm_model_max_async=4,
    llm_model_max_token_size=32768,
    llm_model_kwargs={"host": "http://localhost:11434", "options": {"num_ctx": 32768}},
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embed(
            texts, embed_model="nomic-embed-text", host="http://localhost:11434"
        ),
    ),
)

# H√†m x·ª≠ l√Ω truy v·∫•n v·ªõi 3 mode
def ask_lightRAG(query):
    modes = ["local", "global", "mix"]
    responses = {}

    # Th·ª±c hi·ªán truy v·∫•n cho t·ª´ng mode
    for mode in modes:
        print(f"\nüîé **Truy v·∫•n mode `{mode}`** ...")
        param = QueryParam(mode=mode, stream=True)  # Lu√¥n b·∫≠t stream ƒë·ªÉ ki·ªÉm tra

        resp = rag.query(query, param=param)

        # N·∫øu l√† stream, x·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô
        if inspect.isasyncgen(resp):
            async def print_stream(mode, stream):
                print(f"\nüü¢ **K·∫øt qu·∫£ (mode `{mode}`):**")
                async for chunk in stream:
                    print(chunk, end="", flush=True)
                print("\n" + "-" * 50)  # NgƒÉn c√°ch gi·ªØa c√°c mode
            asyncio.run(print_stream(mode, resp))

        # N·∫øu kh√¥ng ph·∫£i stream, in tr·ª±c ti·∫øp
        else:
            responses[mode] = resp

    # In c√°c k·∫øt qu·∫£ kh√¥ng ph·∫£i stream
    for mode, result in responses.items():
        print(f"\nüü¢ **K·∫øt qu·∫£ (mode `{mode}`):**\n{result}\n" + "-" * 50)


# V√≤ng l·∫∑p nh·∫≠p c√¢u h·ªèi
while True:
    query = input("\nüí¨ Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n (ho·∫∑c g√µ 'exit' ƒë·ªÉ tho√°t): ")
    if query.lower() == "exit":
        break
    ask_lightRAG(query)