import asyncio
import os
import inspect
import logging
from lightrag import LightRAG, QueryParam
from lightrag.llm.ollama import ollama_model_complete, ollama_embed
from lightrag.utils import EmbeddingFunc

WORKING_DIR = "./dickens_ollama"

logging.basicConfig(format="%(levelname)s:%(message)s", level=logging.INFO)

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

def custom_chunking(content, split_by_character=None, split_by_character_only=False, chunk_token_size=250, chunk_overlap_token_size=0, tiktoken_model_name="gpt-4o-mini"):
    chunks = content.split("\n")
    return [{"content": chunk.strip(), "tokens": len(chunk.split()), "metadata": {"book_id": i}} for i, chunk in enumerate(chunks) if chunk.strip()]

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name="gemma2:9b",
    llm_model_max_async=4,
    llm_model_max_token_size=8192,
    llm_model_kwargs={"host": "http://localhost:11434", "options": {"num_ctx": 8192}},
    embedding_func=EmbeddingFunc(
        embedding_dim=768,
        max_token_size=8192,
        func=lambda texts: ollama_embed(
            texts, embed_model="nomic-embed-text", host="http://localhost:11434"
        ),
    ),
    chunking_func=custom_chunking
)

with open("./data/tiki_books_vn.txt", "r", encoding="utf-8") as f:
   rag.insert(f.read())

with open("./data/books_goodreads_en.txt", "r", encoding="utf-8") as f:
   rag.insert(f.read())

# Prompt tÃ¹y chá»‰nh cho chatbot tÆ° váº¥n bÃ¡n sÃ¡ch
system_prompt = """
Báº¡n lÃ  má»™t trá»£ lÃ½ thÃ´ng minh chuyÃªn tÆ° váº¥n vá» sÃ¡ch trÃªn sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  giÃºp ngÆ°á»i dÃ¹ng tÃ¬m kiáº¿m, so sÃ¡nh vÃ  lá»±a chá»n sÃ¡ch phÃ¹ há»£p vá»›i nhu cáº§u cá»§a há» má»™t cÃ¡ch nhanh chÃ³ng, chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ thÃ´ng tin.  

Khi tráº£ lá»i cÃ¢u há»i, hÃ£y Æ°u tiÃªn **cung cáº¥p thÃ´ng tin rÃµ rÃ ng, dá»… hiá»ƒu, sÃºc tÃ­ch vÃ  Ä‘Ãºng trá»ng tÃ¢m**. Náº¿u cÃ³ thá»ƒ, hÃ£y Ä‘á» xuáº¥t cÃ¡c tÃ¹y chá»n sÃ¡ch liÃªn quan hoáº·c gá»£i Ã½ thÃªm nhá»¯ng sÃ¡ch cÃ³ ná»™i dung tÆ°Æ¡ng tá»±.  

**HÆ°á»›ng dáº«n cÃ¡ch tráº£ lá»i:**  
- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» má»™t **cuá»‘n sÃ¡ch cá»¥ thá»ƒ**, hÃ£y cung cáº¥p:  
  - **TiÃªu Ä‘á» sÃ¡ch, tÃ¡c giáº£, nhÃ  xuáº¥t báº£n, nÄƒm xuáº¥t báº£n, thá»ƒ loáº¡i**  
  - **GiÃ¡ cáº£, Æ°u Ä‘Ã£i giáº£m giÃ¡ (náº¿u cÃ³), sá»‘ lÆ°á»£ng Ä‘Ã£ bÃ¡n, Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng**  
  - **NhÃ  bÃ¡n chÃ­nh vÃ  cÃ¡c nhÃ  bÃ¡n khÃ¡c kÃ¨m giÃ¡ bÃ¡n vÃ  link sáº£n pháº©m**  
  - **TÃ³m táº¯t ná»™i dung sÃ¡ch (náº¿u cÃ³ thá»ƒ)**  

- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» **sÃ¡ch theo thá»ƒ loáº¡i, chá»§ Ä‘á» hoáº·c tÃ¡c giáº£**, hÃ£y Ä‘á» xuáº¥t **danh sÃ¡ch sÃ¡ch phÃ¹ há»£p** kÃ¨m thÃ´ng tin cÆ¡ báº£n.  

- Náº¿u ngÆ°á»i dÃ¹ng cáº§n **gá»£i Ã½ sÃ¡ch theo sá»Ÿ thÃ­ch**, hÃ£y Ä‘áº·t thÃªm cÃ¢u há»i Ä‘á»ƒ hiá»ƒu rÃµ nhu cáº§u, sau Ä‘Ã³ Ä‘á» xuáº¥t **3-5 cuá»‘n sÃ¡ch phÃ¹ há»£p**.  

- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» **so sÃ¡nh sÃ¡ch**, hÃ£y cung cáº¥p báº£ng so sÃ¡nh giá»¯a cÃ¡c sÃ¡ch, bao gá»“m **giÃ¡, Ä‘Ã¡nh giÃ¡, ná»™i dung ná»•i báº­t**.  

- Náº¿u ngÆ°á»i dÃ¹ng cÃ³ cÃ¢u há»i chung vá» **mua sÃ¡ch, chÃ­nh sÃ¡ch giao hÃ ng, Ä‘á»•i tráº£**, hÃ£y cung cáº¥p thÃ´ng tin theo chÃ­nh sÃ¡ch cá»§a sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­.  

**LÆ°u Ã½ quan trá»ng:**  
- Tráº£ lá»i thÃ¢n thiá»‡n, ngáº¯n gá»n nhÆ°ng Ä‘áº§y Ä‘á»§.  
- KhÃ´ng bá»‹a Ä‘áº·t thÃ´ng tin náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u, thay vÃ o Ä‘Ã³ hÃ£y nÃ³i "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ y".  
- Khi Ä‘á» xuáº¥t sÃ¡ch, hÃ£y Æ°u tiÃªn sÃ¡ch cÃ³ **Ä‘Ã¡nh giÃ¡ cao, giÃ¡ tá»‘t vÃ  phÃ¹ há»£p vá»›i yÃªu cáº§u ngÆ°á»i dÃ¹ng**.  
- Náº¿u cÃ³ nhiá»u lá»±a chá»n, hÃ£y Ä‘Æ°a ra cÃ¡c tÃ¹y chá»n Ä‘a dáº¡ng (giÃ¡ tháº¥p â€“ trung bÃ¬nh â€“ cao).  

HÃ£y báº¯t Ä‘áº§u tÆ° váº¥n ngay bÃ¢y giá»!
"""

# Perform local search
input = "SÃ¡ch CÃ¢y Cam Ngá»t Cá»§a TÃ´i Ä‘Æ°á»£c sáº£n xuáº¥t bá»Ÿi nhÃ  xuáº¥t báº£n nÃ o?"
print("\n\nğŸ”ğŸ”ğŸ” QUERY: " + input + "\n\n")

# Perform local search
print("\nğŸ” **Truy váº¥n mode `LOCAL`** ...")
response = rag.query(input, param=QueryParam(mode="local", top_k=5), system_prompt=system_prompt)
print("\nğŸŸ¢ **Káº¿t quáº£ (mode `LOCAL`):**\n" + response)

# Perform global search
print("\nğŸ” **Truy váº¥n mode `GLOBAL`** ...")
response = rag.query(input, param=QueryParam(mode="global", top_k=5), system_prompt=system_prompt)
print("\nğŸŸ¢ **Káº¿t quáº£ (mode `GLOBAL`):**\n" + response)

# Perform hybrid search
print("\nğŸ” **Truy váº¥n mode `MIX`** ...")
response = rag.query(input, param=QueryParam(mode="mix", top_k=5), system_prompt=system_prompt)
print("\nğŸŸ¢ **Káº¿t quáº£ (mode `MIX`):**\n" + response)

# stream response
resp = rag.query(
    input,
    param=QueryParam(mode="hybrid", stream=True),
    system_prompt=system_prompt
)

async def print_stream(stream):
    async for chunk in stream:
        print(chunk, end="", flush=True)


if inspect.isasyncgen(resp):
    asyncio.run(print_stream(resp))
else:
    print(resp)
